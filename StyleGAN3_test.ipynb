{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1i6l3HBEzym2hh6YsKMQ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zardian18/Advanced-GANs-inplementation/blob/master/StyleGAN3_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxxBZevKK63v",
        "outputId": "7b1feefc-cff3-4a9e-843a-c02cf6708f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLcrkPRfK_mA",
        "outputId": "eb0ad547-b03c-4fde-a7d1-a18c99fdaabf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d prasunroy/natural-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkeXNAgKLBfe",
        "outputId": "70e0dcfb-87eb-4944-bba3-0cb0baaae36e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading natural-images.zip to /content\n",
            " 96% 328M/342M [00:03<00:00, 133MB/s]\n",
            "100% 342M/342M [00:03<00:00, 102MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspng ninja imageio-ffmpeg==0.4.3\n",
        "!git clone https://github.com/NVlabs/stylegan3\n",
        "!pip install gdown\n",
        "!pip install torch==1.7.0\n",
        "!pip install pillow==9.4.0\n",
        "%cd ./stylegan3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKkgdOwOLI-k",
        "outputId": "4f0db7b8-125e-4b5f-e903-5cff5a66a06d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyspng) (1.25.2)\n",
            "Installing collected packages: ninja, pyspng, imageio-ffmpeg\n",
            "  Attempting uninstall: imageio-ffmpeg\n",
            "    Found existing installation: imageio-ffmpeg 0.4.9\n",
            "    Uninstalling imageio-ffmpeg-0.4.9:\n",
            "      Successfully uninstalled imageio-ffmpeg-0.4.9\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1.1 pyspng-0.1.1\n",
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.17 MiB | 18.66 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pillow==9.4.0 in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "/content/stylegan3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset_tool.py  --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeKYpauSLPNe",
        "outputId": "0dc267bf-5227-451f-8848-fec642c939f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: dataset_tool.py [OPTIONS]\n",
            "\n",
            "  Convert an image dataset into a dataset archive usable with StyleGAN2 ADA\n",
            "  PyTorch.\n",
            "\n",
            "  The input dataset format is guessed from the --source argument:\n",
            "\n",
            "  --source *_lmdb/                    Load LSUN dataset\n",
            "  --source cifar-10-python.tar.gz     Load CIFAR-10 dataset\n",
            "  --source train-images-idx3-ubyte.gz Load MNIST dataset\n",
            "  --source path/                      Recursively load all images from path/\n",
            "  --source dataset.zip                Recursively load all images from dataset.zip\n",
            "\n",
            "  Specifying the output format and path:\n",
            "\n",
            "  --dest /path/to/dir                 Save output files under /path/to/dir\n",
            "  --dest /path/to/dataset.zip         Save output files into /path/to/dataset.zip\n",
            "\n",
            "  The output dataset format can be either an image folder or an uncompressed\n",
            "  zip archive. Zip archives makes it easier to move datasets around file\n",
            "  servers and clusters, and may offer better training performance on network\n",
            "  file systems.\n",
            "\n",
            "  Images within the dataset archive will be stored as uncompressed PNG.\n",
            "  Uncompresed PNGs can be efficiently decoded in the training loop.\n",
            "\n",
            "  Class labels are stored in a file called 'dataset.json' that is stored at\n",
            "  the dataset root folder.  This file has the following structure:\n",
            "\n",
            "  {\n",
            "      \"labels\": [\n",
            "          [\"00000/img00000000.png\",6],\n",
            "          [\"00000/img00000001.png\",9],\n",
            "          ... repeated for every image in the datase\n",
            "          [\"00049/img00049999.png\",1]\n",
            "      ]\n",
            "  }\n",
            "\n",
            "  If the 'dataset.json' file cannot be found, the dataset is interpreted as\n",
            "  not containing class labels.\n",
            "\n",
            "  Image scale/crop and resolution requirements:\n",
            "\n",
            "  Output images must be square-shaped and they must all have the same power-\n",
            "  of-two dimensions.\n",
            "\n",
            "  To scale arbitrary input image size to a specific width and height, use the\n",
            "  --resolution option.  Output resolution will be either the original input\n",
            "  resolution (if resolution was not specified) or the one specified with\n",
            "  --resolution option.\n",
            "\n",
            "  Use the --transform=center-crop or --transform=center-crop-wide options to\n",
            "  apply a center crop transform on the input image.  These options should be\n",
            "  used with the --resolution option.  For example:\n",
            "\n",
            "  python dataset_tool.py --source LSUN/raw/cat_lmdb --dest /tmp/lsun_cat \\\n",
            "      --transform=center-crop-wide --resolution=512x384\n",
            "\n",
            "Options:\n",
            "  --source PATH                   Directory or archive name for input dataset\n",
            "                                  [required]\n",
            "  --dest PATH                     Output directory or archive name for output\n",
            "                                  dataset  [required]\n",
            "  --max-images INTEGER            Output only up to `max-images` images\n",
            "  --transform [center-crop|center-crop-wide]\n",
            "                                  Input crop/resize mode\n",
            "  --resolution WxH                Output resolution (e.g., '512x512')\n",
            "  --help                          Show this message and exit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/natural-images.zip"
      ],
      "metadata": {
        "id": "n_za99BVMN0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joRwCATLOiTY",
        "outputId": "83acf382-3a4d-4aaa-b9cb-2a5056ff8374"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_spectra.py\t dnnlib\t\t  gen_images.py  LICENSE.txt\t torch_utils\tviz\n",
            "calc_metrics.py  Dockerfile\t  gen_video.py\t metrics\t training\n",
            "data\t\t docs\t\t  gui_utils\t natural_images  train.py\n",
            "dataset_tool.py  environment.yml  legacy.py\t README.md\t visualizer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset_tool.py --source=/content/stylegan3/data/natural_images/car --dest=/content/stylegan3/generated_folder/cars2.zip --resolution=64x64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvN5BqAyLg5w",
        "outputId": "47b44169-c2d4-4483-878a-8edbdd5b5f16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 968/968 [00:01<00:00, 856.38it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KycCJ_CfSm3r",
        "outputId": "ba5f407b-84de-41b9-9304-8c113c8e4721"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: train.py [OPTIONS]\n",
            "\n",
            "  Train a GAN using the techniques described in the paper \"Alias-Free\n",
            "  Generative Adversarial Networks\".\n",
            "\n",
            "  Examples:\n",
            "\n",
            "  # Train StyleGAN3-T for AFHQv2 using 8 GPUs.\n",
            "  python train.py --outdir=~/training-runs --cfg=stylegan3-t --data=~/datasets/afhqv2-512x512.zip \\\n",
            "      --gpus=8 --batch=32 --gamma=8.2 --mirror=1\n",
            "\n",
            "  # Fine-tune StyleGAN3-R for MetFaces-U using 1 GPU, starting from the pre-trained FFHQ-U pickle.\n",
            "  python train.py --outdir=~/training-runs --cfg=stylegan3-r --data=~/datasets/metfacesu-1024x1024.zip \\\n",
            "      --gpus=8 --batch=32 --gamma=6.6 --mirror=1 --kimg=5000 --snap=5 \\\n",
            "      --resume=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhqu-1024x1024.pkl\n",
            "\n",
            "  # Train StyleGAN2 for FFHQ at 1024x1024 resolution using 8 GPUs.\n",
            "  python train.py --outdir=~/training-runs --cfg=stylegan2 --data=~/datasets/ffhq-1024x1024.zip \\\n",
            "      --gpus=8 --batch=32 --gamma=10 --mirror=1 --aug=noaug\n",
            "\n",
            "Options:\n",
            "  --outdir DIR                    Where to save the results  [required]\n",
            "  --cfg [stylegan3-t|stylegan3-r|stylegan2]\n",
            "                                  Base configuration  [required]\n",
            "  --data [ZIP|DIR]                Training data  [required]\n",
            "  --gpus INT                      Number of GPUs to use  [x>=1; required]\n",
            "  --batch INT                     Total batch size  [x>=1; required]\n",
            "  --gamma FLOAT                   R1 regularization weight  [x>=0; required]\n",
            "  --cond BOOL                     Train conditional model  [default: False]\n",
            "  --mirror BOOL                   Enable dataset x-flips  [default: False]\n",
            "  --aug [noaug|ada|fixed]         Augmentation mode  [default: ada]\n",
            "  --resume [PATH|URL]             Resume from given network pickle\n",
            "  --freezed INT                   Freeze first layers of D  [default: 0; x>=0]\n",
            "  --p FLOAT                       Probability for --aug=fixed  [default: 0.2;\n",
            "                                  0<=x<=1]\n",
            "  --target FLOAT                  Target value for --aug=ada  [default: 0.6;\n",
            "                                  0<=x<=1]\n",
            "  --batch-gpu INT                 Limit batch size per GPU  [x>=1]\n",
            "  --cbase INT                     Capacity multiplier  [default: 32768; x>=1]\n",
            "  --cmax INT                      Max. feature maps  [default: 512; x>=1]\n",
            "  --glr FLOAT                     G learning rate  [default: varies]  [x>=0]\n",
            "  --dlr FLOAT                     D learning rate  [default: 0.002; x>=0]\n",
            "  --map-depth INT                 Mapping network depth  [default: varies]\n",
            "                                  [x>=1]\n",
            "  --mbstd-group INT               Minibatch std group size  [default: 4; x>=1]\n",
            "  --desc STR                      String to include in result dir name\n",
            "  --metrics [NAME|A,B,C|none]     Quality metrics  [default: fid50k_full]\n",
            "  --kimg KIMG                     Total training duration  [default: 25000;\n",
            "                                  x>=1]\n",
            "  --tick KIMG                     How often to print progress  [default: 4;\n",
            "                                  x>=1]\n",
            "  --snap TICKS                    How often to save snapshots  [default: 50;\n",
            "                                  x>=1]\n",
            "  --seed INT                      Random seed  [default: 0; x>=0]\n",
            "  --fp32 BOOL                     Disable mixed-precision  [default: False]\n",
            "  --nobench BOOL                  Disable cuDNN benchmarking  [default: False]\n",
            "  --workers INT                   DataLoader worker processes  [default: 3;\n",
            "                                  x>=1]\n",
            "  -n, --dry-run                   Print training options and exit\n",
            "  --help                          Show this message and exit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir=~/training-runs --cfg=stylegan3-t --data=/content/stylegan3/generated_folder/cars2.zip --gpus=1 --batch=8 --gamma=8.2 --mirror=False --kimg=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inq65S6hPaXa",
        "outputId": "0b78dbde-2044-407a-e9f8-3f4c1fec6586"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9997227795604651\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 8.2\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/stylegan3/generated_folder/cars2.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 968,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 64,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 8,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 10,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 2.5,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"~/training-runs/00002-stylegan3-t-cars2-gpus1-batch8-gamma8.2\"\n",
            "}\n",
            "\n",
            "Output directory:    ~/training-runs/00002-stylegan3-t-cars2-gpus1-batch8-gamma8.2\n",
            "Number of GPUs:      1\n",
            "Batch size:          8 images\n",
            "Training duration:   10 kimg\n",
            "Dataset path:        /content/stylegan3/generated_folder/cars2.zip\n",
            "Dataset size:        968 images\n",
            "Dataset resolution:  64\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  968\n",
            "Image shape: [3, 64, 64]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                    Parameters  Buffers  Output shape      Datatype\n",
            "---                          ---         ---      ---               ---     \n",
            "mapping.fc0                  262656      -        [8, 512]          float32 \n",
            "mapping.fc1                  262656      -        [8, 512]          float32 \n",
            "mapping                      -           512      [8, 16, 512]      float32 \n",
            "synthesis.input.affine       2052        -        [8, 4]            float32 \n",
            "synthesis.input              262144      1545     [8, 512, 36, 36]  float32 \n",
            "synthesis.L0_36_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L0_36_512          2359808     25       [8, 512, 36, 36]  float16 \n",
            "synthesis.L1_36_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L1_36_512          2359808     25       [8, 512, 36, 36]  float16 \n",
            "synthesis.L2_36_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L2_36_512          2359808     25       [8, 512, 36, 36]  float16 \n",
            "synthesis.L3_36_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L3_36_512          2359808     25       [8, 512, 36, 36]  float16 \n",
            "synthesis.L4_52_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L4_52_512          2359808     37       [8, 512, 52, 52]  float16 \n",
            "synthesis.L5_52_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L5_52_512          2359808     25       [8, 512, 52, 52]  float16 \n",
            "synthesis.L6_52_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L6_52_512          2359808     25       [8, 512, 52, 52]  float16 \n",
            "synthesis.L7_52_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L7_52_512          2359808     25       [8, 512, 52, 52]  float16 \n",
            "synthesis.L8_84_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L8_84_512          2359808     37       [8, 512, 84, 84]  float16 \n",
            "synthesis.L9_84_512.affine   262656      -        [8, 512]          float32 \n",
            "synthesis.L9_84_512          2359808     25       [8, 512, 84, 84]  float16 \n",
            "synthesis.L10_84_512.affine  262656      -        [8, 512]          float32 \n",
            "synthesis.L10_84_512         2359808     25       [8, 512, 84, 84]  float16 \n",
            "synthesis.L11_84_512.affine  262656      -        [8, 512]          float32 \n",
            "synthesis.L11_84_512         2359808     25       [8, 512, 84, 84]  float16 \n",
            "synthesis.L12_84_512.affine  262656      -        [8, 512]          float32 \n",
            "synthesis.L12_84_512         2359808     25       [8, 512, 84, 84]  float16 \n",
            "synthesis.L13_64_512.affine  262656      -        [8, 512]          float32 \n",
            "synthesis.L13_64_512         2359808     25       [8, 512, 64, 64]  float16 \n",
            "synthesis.L14_64_3.affine    262656      -        [8, 512]          float32 \n",
            "synthesis.L14_64_3           1539        1        [8, 3, 64, 64]    float16 \n",
            "synthesis                    -           -        [8, 3, 64, 64]    float32 \n",
            "---                          ---         ---      ---               ---     \n",
            "Total                        37768199    2432     -                 -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape      Datatype\n",
            "---            ---         ---      ---               ---     \n",
            "b64.fromrgb    2048        16       [8, 512, 64, 64]  float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]  float16 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]  float16 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]  float16 \n",
            "b64            -           16       [8, 512, 32, 32]  float16 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]  float16 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]  float16 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]  float16 \n",
            "b32            -           16       [8, 512, 16, 16]  float16 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]    float16 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]  float16 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]    float16 \n",
            "b16            -           16       [8, 512, 8, 8]    float16 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]    float16 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]    float16 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]    float16 \n",
            "b8             -           16       [8, 512, 4, 4]    float16 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]    float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]    float32 \n",
            "b4.fc          4194816     -        [8, 512]          float32 \n",
            "b4.out         513         -        [8, 1]            float32 \n",
            "---            ---         ---      ---               ---     \n",
            "Total          26488833    288      -                 -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-02-23 14:12:21.562037: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-23 14:12:21.562091: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-23 14:12:21.563382: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-23 14:12:22.862414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 10 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 50s          sec/tick 7.5     sec/kimg 934.16  maintenance 42.7   cpumem 2.12   gpumem 11.65  reserved 11.79  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir=~/training-runs --data=/content/stylegan3/generated_folder/cars2.zip --cfg=stylegan3-r --gpus=1 --batch=8 --gamma=8.2 --mirror=False --kimg=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfH6cEvqVp-3",
        "outputId": "8782e888-3cbb-406c-aa92-c4e3bfe04fde"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 65536,\n",
            "    \"channel_max\": 1024,\n",
            "    \"magnitude_ema_beta\": 0.9997227795604651,\n",
            "    \"conv_kernel\": 1,\n",
            "    \"use_radial_filters\": true\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 8.2,\n",
            "    \"blur_init_sigma\": 10,\n",
            "    \"blur_fade_kimg\": 50.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/stylegan3/generated_folder/cars2.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 968,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 64,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 8,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 10,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 2.5,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"~/training-runs/00003-stylegan3-r-cars2-gpus1-batch8-gamma8.2\"\n",
            "}\n",
            "\n",
            "Output directory:    ~/training-runs/00003-stylegan3-r-cars2-gpus1-batch8-gamma8.2\n",
            "Number of GPUs:      1\n",
            "Batch size:          8 images\n",
            "Training duration:   10 kimg\n",
            "Dataset path:        /content/stylegan3/generated_folder/cars2.zip\n",
            "Dataset size:        968 images\n",
            "Dataset resolution:  64\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  968\n",
            "Image shape: [3, 64, 64]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape       Datatype\n",
            "---                           ---         ---      ---                ---     \n",
            "mapping.fc0                   262656      -        [8, 512]           float32 \n",
            "mapping.fc1                   262656      -        [8, 512]           float32 \n",
            "mapping                       -           512      [8, 16, 512]       float32 \n",
            "synthesis.input.affine        2052        -        [8, 4]             float32 \n",
            "synthesis.input               1048576     3081     [8, 1024, 36, 36]  float32 \n",
            "synthesis.L0_36_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L0_36_1024          1049600     157      [8, 1024, 36, 36]  float16 \n",
            "synthesis.L1_36_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L1_36_1024          1049600     157      [8, 1024, 36, 36]  float16 \n",
            "synthesis.L2_36_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L2_36_1024          1049600     157      [8, 1024, 36, 36]  float16 \n",
            "synthesis.L3_36_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L3_36_1024          1049600     157      [8, 1024, 36, 36]  float16 \n",
            "synthesis.L4_52_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L4_52_1024          1049600     169      [8, 1024, 52, 52]  float16 \n",
            "synthesis.L5_52_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L5_52_1024          1049600     157      [8, 1024, 52, 52]  float16 \n",
            "synthesis.L6_52_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L6_52_1024          1049600     157      [8, 1024, 52, 52]  float16 \n",
            "synthesis.L7_52_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L7_52_1024          1049600     157      [8, 1024, 52, 52]  float16 \n",
            "synthesis.L8_84_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L8_84_1024          1049600     169      [8, 1024, 84, 84]  float16 \n",
            "synthesis.L9_84_1024.affine   525312      -        [8, 1024]          float32 \n",
            "synthesis.L9_84_1024          1049600     157      [8, 1024, 84, 84]  float16 \n",
            "synthesis.L10_84_1024.affine  525312      -        [8, 1024]          float32 \n",
            "synthesis.L10_84_1024         1049600     157      [8, 1024, 84, 84]  float16 \n",
            "synthesis.L11_84_1024.affine  525312      -        [8, 1024]          float32 \n",
            "synthesis.L11_84_1024         1049600     157      [8, 1024, 84, 84]  float16 \n",
            "synthesis.L12_84_1024.affine  525312      -        [8, 1024]          float32 \n",
            "synthesis.L12_84_1024         1049600     25       [8, 1024, 84, 84]  float16 \n",
            "synthesis.L13_64_1024.affine  525312      -        [8, 1024]          float32 \n",
            "synthesis.L13_64_1024         1049600     25       [8, 1024, 64, 64]  float16 \n",
            "synthesis.L14_64_3.affine     525312      -        [8, 1024]          float32 \n",
            "synthesis.L14_64_3            3075        1        [8, 3, 64, 64]     float16 \n",
            "synthesis                     -           -        [8, 3, 64, 64]     float32 \n",
            "---                           ---         ---      ---                ---     \n",
            "Total                         24153095    5552     -                  -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape      Datatype\n",
            "---            ---         ---      ---               ---     \n",
            "b64.fromrgb    2048        16       [8, 512, 64, 64]  float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]  float16 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]  float16 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]  float16 \n",
            "b64            -           16       [8, 512, 32, 32]  float16 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]  float16 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]  float16 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]  float16 \n",
            "b32            -           16       [8, 512, 16, 16]  float16 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]    float16 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]  float16 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]    float16 \n",
            "b16            -           16       [8, 512, 8, 8]    float16 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]    float16 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]    float16 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]    float16 \n",
            "b8             -           16       [8, 512, 4, 4]    float16 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]    float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]    float32 \n",
            "b4.fc          4194816     -        [8, 512]          float32 \n",
            "b4.out         513         -        [8, 1]            float32 \n",
            "---            ---         ---      ---               ---     \n",
            "Total          26488833    288      -                 -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-02-23 14:22:42.743400: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-23 14:22:42.743451: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-23 14:22:42.744769: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-23 14:22:43.724475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 10 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 47s          sec/tick 7.7     sec/kimg 966.90  maintenance 39.2   cpumem 2.08   gpumem 11.36  reserved 11.43  augment 0.000\n",
            "Evaluating metrics...\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir=~/training-runs --data=/content/stylegan3/generated_folder/cars.zip --cfg=stylegan3-r --gpus=1 --batch=8 --gamma=8.2 --mirror=False --kimg=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtPZGDcQX-OF",
        "outputId": "287eda82-ea05-4822-d541-7ac84464b5c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 65536,\n",
            "    \"channel_max\": 1024,\n",
            "    \"magnitude_ema_beta\": 0.9997227795604651,\n",
            "    \"conv_kernel\": 1,\n",
            "    \"use_radial_filters\": true\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 8.2,\n",
            "    \"blur_init_sigma\": 10,\n",
            "    \"blur_fade_kimg\": 50.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/stylegan3/generated_folder/cars.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 968,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 8,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 10,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 2.5,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"~/training-runs/00004-stylegan3-r-cars-gpus1-batch8-gamma8.2\"\n",
            "}\n",
            "\n",
            "Output directory:    ~/training-runs/00004-stylegan3-r-cars-gpus1-batch8-gamma8.2\n",
            "Number of GPUs:      1\n",
            "Batch size:          8 images\n",
            "Training duration:   10 kimg\n",
            "Dataset path:        /content/stylegan3/generated_folder/cars.zip\n",
            "Dataset size:        968 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  968\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [8, 512]             float32 \n",
            "mapping.fc1                   262656      -        [8, 512]             float32 \n",
            "mapping                       -           512      [8, 16, 512]         float32 \n",
            "synthesis.input.affine        2052        -        [8, 4]               float32 \n",
            "synthesis.input               1048576     3081     [8, 1024, 36, 36]    float32 \n",
            "synthesis.L0_36_1024.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L0_36_1024          1049600     157      [8, 1024, 36, 36]    float32 \n",
            "synthesis.L1_36_1024.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L1_36_1024          1049600     157      [8, 1024, 36, 36]    float32 \n",
            "synthesis.L2_36_1024.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L2_36_1024          1049600     157      [8, 1024, 36, 36]    float32 \n",
            "synthesis.L3_52_1024.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L3_52_1024          1049600     169      [8, 1024, 52, 52]    float16 \n",
            "synthesis.L4_52_1024.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L4_52_1024          1049600     157      [8, 1024, 52, 52]    float16 \n",
            "synthesis.L5_84_1024.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L5_84_1024          1049600     169      [8, 1024, 84, 84]    float16 \n",
            "synthesis.L6_84_1024.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L6_84_1024          1049600     157      [8, 1024, 84, 84]    float16 \n",
            "synthesis.L7_148_1024.affine  525312      -        [8, 1024]            float32 \n",
            "synthesis.L7_148_1024         1049600     169      [8, 1024, 148, 148]  float16 \n",
            "synthesis.L8_148_1024.affine  525312      -        [8, 1024]            float32 \n",
            "synthesis.L8_148_1024         1049600     157      [8, 1024, 148, 148]  float16 \n",
            "synthesis.L9_148_724.affine   525312      -        [8, 1024]            float32 \n",
            "synthesis.L9_148_724          742100      157      [8, 724, 148, 148]   float16 \n",
            "synthesis.L10_276_512.affine  371412      -        [8, 724]             float32 \n",
            "synthesis.L10_276_512         371200      169      [8, 512, 276, 276]   float16 \n",
            "synthesis.L11_276_362.affine  262656      -        [8, 512]             float32 \n",
            "synthesis.L11_276_362         185706      157      [8, 362, 276, 276]   float16 \n",
            "synthesis.L12_276_256.affine  185706      -        [8, 362]             float32 \n",
            "synthesis.L12_276_256         92928       25       [8, 256, 276, 276]   float16 \n",
            "synthesis.L13_256_256.affine  131328      -        [8, 256]             float32 \n",
            "synthesis.L13_256_256         65792       25       [8, 256, 256, 256]   float16 \n",
            "synthesis.L14_256_3.affine    131328      -        [8, 256]             float32 \n",
            "synthesis.L14_256_3           771         1        [8, 3, 256, 256]     float16 \n",
            "synthesis                     -           -        [8, 3, 256, 256]     float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         18816387    5576     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape        Datatype\n",
            "---            ---         ---      ---                 ---     \n",
            "b256.fromrgb   512         16       [8, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [8, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [8, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [8, 256, 128, 128]  float16 \n",
            "b256           -           16       [8, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [8, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [8, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [8, 512, 64, 64]    float16 \n",
            "b128           -           16       [8, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [8, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [8, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [8, 512, 32, 32]    float16 \n",
            "b64            -           16       [8, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [8, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [8, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [8, 512, 16, 16]    float16 \n",
            "b32            -           16       [8, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [8, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [8, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [8, 512, 8, 8]      float32 \n",
            "b16            -           16       [8, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [8, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [8, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [8, 512, 4, 4]      float32 \n",
            "b8             -           16       [8, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [8, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [8, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [8, 512]            float32 \n",
            "b4.out         513         -        [8, 1]              float32 \n",
            "---            ---         ---      ---                 ---     \n",
            "Total          28864129    416      -                   -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-02-23 14:31:52.780654: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-23 14:31:52.780711: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-23 14:31:52.782017: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-23 14:31:53.896717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 10 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 1m 40s       sec/tick 26.8    sec/kimg 3350.74 maintenance 73.1   cpumem 2.60   gpumem 10.80  reserved 10.88  augment 0.000\n",
            "Evaluating metrics...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir=~/training-runs --data=/content/stylegan3/generated_folder/cars.zip --cfg=stylegan3-t --gpus=1 --batch=32 --gamma=8.2 --mirror=False --kimg=100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnbHMNNZcDPh",
        "outputId": "e44dad8d-5d32-414c-89a4-54fef2b8e909"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9988915792636801\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 8.2\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/stylegan3/generated_folder/cars.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 968,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 32,\n",
            "  \"batch_gpu\": 32,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 100,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 10.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"~/training-runs/00005-stylegan3-t-cars-gpus1-batch32-gamma8.2\"\n",
            "}\n",
            "\n",
            "Output directory:    ~/training-runs/00005-stylegan3-t-cars-gpus1-batch32-gamma8.2\n",
            "Number of GPUs:      1\n",
            "Batch size:          32 images\n",
            "Training duration:   100 kimg\n",
            "Dataset path:        /content/stylegan3/generated_folder/cars.zip\n",
            "Dataset size:        968 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  968\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [32, 512]            float32 \n",
            "mapping.fc1                   262656      -        [32, 512]            float32 \n",
            "mapping                       -           512      [32, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [32, 4]              float32 \n",
            "synthesis.input               262144      1545     [32, 512, 36, 36]    float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [32, 512]            float32 \n",
            "synthesis.L0_36_512           2359808     25       [32, 512, 36, 36]    float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [32, 512]            float32 \n",
            "synthesis.L1_36_512           2359808     25       [32, 512, 36, 36]    float32 \n",
            "synthesis.L2_36_512.affine    262656      -        [32, 512]            float32 \n",
            "synthesis.L2_36_512           2359808     25       [32, 512, 36, 36]    float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [32, 512]            float32 \n",
            "synthesis.L3_52_512           2359808     37       [32, 512, 52, 52]    float16 \n",
            "synthesis.L4_52_512.affine    262656      -        [32, 512]            float32 \n",
            "synthesis.L4_52_512           2359808     25       [32, 512, 52, 52]    float16 \n",
            "synthesis.L5_84_512.affine    262656      -        [32, 512]            float32 \n",
            "synthesis.L5_84_512           2359808     37       [32, 512, 84, 84]    float16 \n",
            "synthesis.L6_84_512.affine    262656      -        [32, 512]            float32 \n",
            "synthesis.L6_84_512           2359808     25       [32, 512, 84, 84]    float16 \n",
            "synthesis.L7_148_512.affine   262656      -        [32, 512]            float32 \n",
            "synthesis.L7_148_512          2359808     37       [32, 512, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   262656      -        [32, 512]            float32 \n",
            "synthesis.L8_148_512          2359808     25       [32, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [32, 512]            float32 \n",
            "synthesis.L9_148_362          1668458     25       [32, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [32, 362]            float32 \n",
            "synthesis.L10_276_256         834304      37       [32, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [32, 256]            float32 \n",
            "synthesis.L11_276_181         417205      25       [32, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [32, 181]            float32 \n",
            "synthesis.L12_276_128         208640      25       [32, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [32, 128]            float32 \n",
            "synthesis.L13_256_128         147584      25       [32, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [32, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [32, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [32, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         28472133    2456     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   512         16       [32, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [32, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [32, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [32, 256, 128, 128]  float16 \n",
            "b256           -           16       [32, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [32, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [32, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [32, 512, 64, 64]    float16 \n",
            "b128           -           16       [32, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [32, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [32, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [32, 512, 32, 32]    float16 \n",
            "b64            -           16       [32, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [32, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [32, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [32, 512, 16, 16]    float16 \n",
            "b32            -           16       [32, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [32, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [32, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [32, 512, 8, 8]      float32 \n",
            "b16            -           16       [32, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [32, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [32, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [32, 512, 4, 4]      float32 \n",
            "b8             -           16       [32, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [32, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [32, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [32, 512]            float32 \n",
            "b4.out         513         -        [32, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          28864129    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2024-02-23 14:50:14.511764: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-23 14:50:14.511819: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-23 14:50:14.513157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-23 14:50:15.631777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training for 100 kimg...\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan3/train.py\", line 286, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/content/stylegan3/train.py\", line 281, in main\n",
            "    launch_training(c=c, desc=desc, outdir=opts.outdir, dry_run=opts.dry_run)\n",
            "  File \"/content/stylegan3/train.py\", line 96, in launch_training\n",
            "    subprocess_fn(rank=0, c=c, temp_dir=temp_dir)\n",
            "  File \"/content/stylegan3/train.py\", line 47, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **c)\n",
            "  File \"/content/stylegan3/training/training_loop.py\", line 278, in training_loop\n",
            "    loss.accumulate_gradients(phase=phase.name, real_img=real_img, real_c=real_c, gen_z=gen_z, gen_c=gen_c, gain=phase.interval, cur_nimg=cur_nimg)\n",
            "  File \"/content/stylegan3/training/loss.py\", line 74, in accumulate_gradients\n",
            "    gen_img, _gen_ws = self.run_G(gen_z, gen_c)\n",
            "  File \"/content/stylegan3/training/loss.py\", line 49, in run_G\n",
            "    img = self.G.synthesis(ws, update_emas=update_emas)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/stylegan3/training/networks_stylegan3.py\", line 471, in forward\n",
            "    x = getattr(self, name)(x, w, **layer_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/stylegan3/training/networks_stylegan3.py\", line 355, in forward\n",
            "    x = filtered_lrelu.filtered_lrelu(x=x, fu=self.up_filter, fd=self.down_filter, b=self.bias.to(x.dtype),\n",
            "  File \"/content/stylegan3/torch_utils/ops/filtered_lrelu.py\", line 115, in filtered_lrelu\n",
            "    return _filtered_lrelu_cuda(up=up, down=down, padding=padding, gain=gain, slope=slope, clamp=clamp, flip_filter=flip_filter).apply(x, fu, fd, b, None, 0, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\", line 539, in apply\n",
            "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
            "  File \"/content/stylegan3/torch_utils/ops/filtered_lrelu.py\", line 217, in forward\n",
            "    y, so, return_code = _plugin.filtered_lrelu(x, fu, fd, b, si, up, down, px0, px1, py0, py1, sx, sy, gain, slope, clamp, flip_filter, write_signs)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 596.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 421.06 MiB is free. Process 203003 has 14.33 GiB memory in use. Of the allocated memory 13.38 GiB is allocated by PyTorch, and 838.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !python gen_images.py --outdir=out --trunc=1 --seeds=2 \\\n",
        "#     --network=https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-afhqv2-512x512.pkl"
      ],
      "metadata": {
        "id": "zeKHJCPXMhqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.imread(\"/content/stylegan3/finalData/car/car_0000.jpg\")"
      ],
      "metadata": {
        "id": "iUpYe9BeOvby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gen_images.py --outdir=out --trunc=1 --seeds=2 --network=results/{something}.pkl"
      ],
      "metadata": {
        "id": "saI5G0lBPEIs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}